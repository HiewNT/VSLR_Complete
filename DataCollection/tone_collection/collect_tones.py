#!/usr/bin/env python3
"""
Script thu tháº­p dá»¯ liá»‡u dáº¥u thanh cho VSLR_Complete
Dá»±a trÃªn VSLR_DauThanh/collect_data.py
"""

import sys
import cv2
import os
import time
import numpy as np
import json
from pathlib import Path
from collections import deque

# Add parent directory to path for imports
sys.path.append(str(Path(__file__).parent.parent.parent))

from Recognition.character_recognition.hand_tracking import handDetector

class ToneDataCollector:
    """Class thu tháº­p dá»¯ liá»‡u dáº¥u thanh giá»‘ng VSLR_DauThanh"""
    
    def __init__(self, data_dir="data/tones"):
        """Khá»Ÿi táº¡o ToneDataCollector"""
        self.data_dir = Path(data_dir)
        self.keypoints_dir = self.data_dir / "keypoints"
        self.keypoints_dir.mkdir(parents=True, exist_ok=True)
        
        # Khá»Ÿi táº¡o hand detector
        self.detector = handDetector(maxHands=1)
        
        # CÃ¡c tham sá»‘ thu tháº­p
        self.total_frames = 30  # ChÃ­nh xÃ¡c 30 frame
        self.fps = 20  # FPS cá»§a video
        
        # CÃ¡c lá»›p dáº¥u thanh
        self.classes = ['huyen', 'sac', 'hoi', 'nga', 'nang']
        self.class_names = {
            'huyen': 'huyen',
            'sac': 'sac', 
            'hoi': 'hoi',
            'nga': 'nga',
            'nang': 'nang'
        }
        
        # Tráº¡ng thÃ¡i hiá»‡n táº¡i
        self.current_class = 0  # Index cá»§a lá»›p hiá»‡n táº¡i
        self.is_recording = False
        self.recording_frames = []
        self.frame_count = 0
        
        # Thá»‘ng kÃª
        self.stats = self.get_data_statistics()
        
        print("=== Há»† THá»NG THU THáº¬P Dá»® LIá»†U Dáº¤U THANH ===")
        print(f"Sá»‘ frame: {self.total_frames}")
        print(f"FPS: {self.fps}")
        print("CÃ¡c lá»›p dáº¥u thanh:")
        for i, (cls, name) in enumerate(self.class_names.items(), 1):
            print(f"  {i}. {cls}: {name}")
        print("\nÄIá»€U KHIá»‚N:")
        print("  1-5: Chá»n dáº¥u thanh")
        print("  SPACE: Báº¯t Ä‘áº§u thu tháº­p")
        print("  Q: ThoÃ¡t")
    
    def get_next_sample_id(self, class_name: str) -> int:
        """Láº¥y ID máº«u tiáº¿p theo cho lá»›p"""
        class_dir = self.keypoints_dir / class_name
        if not class_dir.exists():
            return 0
        
        existing_samples = [f for f in class_dir.glob('*.npy')]
        return len(existing_samples)
    
    def start_recording(self):
        """Báº¯t Ä‘áº§u thu tháº­p video"""
        if self.is_recording:
            return
        
        self.is_recording = True
        self.recording_frames = []
        self.frame_count = 0
        self.sample_id = self.get_next_sample_id(self.classes[self.current_class])
        print(f"\nðŸŽ¬ Báº¯t Ä‘áº§u thu tháº­p {self.class_names[self.classes[self.current_class]]} (ID: {self.sample_id})")
    
    def stop_recording(self):
        """Dá»«ng thu tháº­p video"""
        if not self.is_recording:
            return
        self.is_recording = False
        if len(self.recording_frames) == self.total_frames:
            class_name = self.classes[self.current_class]
            # Sá»­ dá»¥ng numpy array Ä‘á»ƒ giáº£m overhead khi lÆ°u
            frames_array = np.stack(self.recording_frames)
            self.save_keypoints(frames_array, class_name, self.sample_id)
            self.stats[class_name] += 1
            self.stats['total'] += 1
            print(f"âœ… ÄÃ£ lÆ°u {len(self.recording_frames)} frames cho {self.class_names[class_name]} (ID: {self.sample_id})")
        else:
            print(f"âŒ Thu tháº­p khÃ´ng thÃ nh cÃ´ng! Chá»‰ cÃ³ {len(self.recording_frames)} frames")
        self.recording_frames.clear()
        self.frame_count = 0

    def save_keypoints(self, keypoints: np.ndarray, class_name: str, sample_id: int):
        """LÆ°u keypoints vÃ o file giá»‘ng VSLR_DauThanh"""
        if class_name not in self.classes:
            raise ValueError(f"Class {class_name} khÃ´ng há»£p lá»‡. CÃ¡c lá»›p há»£p lá»‡: {self.classes}")
        
        class_dir = self.keypoints_dir / class_name
        class_dir.mkdir(exist_ok=True)
        
        # LÆ°u keypoints
        file_path = class_dir / f"sample_{sample_id:04d}.npy"
        np.save(file_path, keypoints.astype(np.float32))
        
        # LÆ°u metadata
        metadata = {
            'class': class_name,
            'sample_id': sample_id,
            'num_frames': len(keypoints),
            'keypoints_shape': keypoints.shape
        }
        
        metadata_path = class_dir / f"sample_{sample_id:04d}_metadata.json"
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
    
    def get_data_statistics(self) -> dict:
        """Láº¥y thá»‘ng kÃª dá»¯ liá»‡u"""
        stats = {}
        
        for cls in self.classes:
            class_dir = self.keypoints_dir / cls
            if class_dir.exists():
                num_samples = len(list(class_dir.glob('*.npy')))
                stats[cls] = num_samples
            else:
                stats[cls] = 0
        
        stats['total'] = sum(stats.values())
        stats['classes'] = self.classes
        
        return stats

    def process_frame(self, frame):
        """Xá»­ lÃ½ frame vÃ  trÃ­ch xuáº¥t keypoints"""
        hands, frame = self.detector.findHands(frame, draw=True)
        
        # Sá»­ dá»¥ng biáº¿n static cho frame trá»‘ng Ä‘á»ƒ trÃ¡nh táº¡o má»›i liÃªn tá»¥c
        if not hasattr(self, '_empty_keypoints'):
            self._empty_keypoints = np.zeros(63)
        
        if hands:
            hand = hands[0]
            if 'landmark' in hand:
                # TrÃ­ch xuáº¥t keypoints giá»‘ng VSLR_DauThanh
                keypoints = np.array([[lm.x, lm.y, lm.z] for lm in hand['landmark']]).flatten()
                if self.is_recording:
                    self.recording_frames.append(keypoints)
                    self.frame_count += 1
        else:
            if self.is_recording:
                self.recording_frames.append(self._empty_keypoints)
                self.frame_count += 1
        
        return frame
    
    def draw_ui(self, frame):
        """Váº½ giao diá»‡n ngÆ°á»i dÃ¹ng lÃªn frame giá»‘ng VSLR_DauThanh"""
        # ThÃ´ng tin lá»›p hiá»‡n táº¡i
        current_class_name = self.class_names[self.classes[self.current_class]]
        cv2.putText(frame, f"Dau thanh: {current_class_name}", (10, 60), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        
        # Thá»‘ng kÃª lá»›p hiá»‡n táº¡i
        current_count = self.stats.get(self.classes[self.current_class], 0)
        cv2.putText(frame, f"Label: {current_count}", (10, 90), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        
        # Tráº¡ng thÃ¡i thu tháº­p
        if self.is_recording:
            cv2.putText(frame, f"Thu tháº­p: {self.frame_count}/{self.total_frames}", (10, 120), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            
            # Váº½ progress bar
            progress = self.frame_count / self.total_frames
            bar_width = 200
            bar_height = 20
            bar_x, bar_y = 10, 150
            
            cv2.rectangle(frame, (bar_x, bar_y), (bar_x + bar_width, bar_y + bar_height), (128, 128, 128), 2)
            fill_width = int(bar_width * progress)
            cv2.rectangle(frame, (bar_x, bar_y), (bar_x + fill_width, bar_y + bar_height), (0, 255, 0), -1)
            
            if self.frame_count >= self.total_frames:
                cv2.putText(frame, "HoÃ n thÃ nh!", (10, 190), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        else:
            cv2.putText(frame, "Enter Space to begin:", (10, 120), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        # Danh sÃ¡ch cÃ¡c lá»›p
        y_offset = 220
        for i, (cls, name) in enumerate(self.class_names.items()):
            color = (0, 255, 0) if i == self.current_class else (128, 128, 128)
            count = self.stats.get(cls, 0)
            cv2.putText(frame, f"{i+1}. {name}: {count} máº«u", (10, y_offset + i*25), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
        
        # Tá»•ng thá»‘ng kÃª
        cv2.putText(frame, f"Total: {self.stats['total']} mau", (10, 470), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
    
    def run(self):
        """Cháº¡y há»‡ thá»‘ng thu tháº­p dá»¯ liá»‡u"""
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            print("KhÃ´ng thá»ƒ má»Ÿ camera!")
            return
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        cap.set(cv2.CAP_PROP_FPS, self.fps)
        print("Báº¯t Ä‘áº§u hiá»ƒn thá»‹ camera...")
        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                frame = self.process_frame(frame)
                self.draw_ui(frame)
                if self.is_recording and self.frame_count >= self.total_frames:
                    self.stop_recording()
                cv2.imshow('Thu tháº­p dá»¯ liá»‡u dáº¥u thanh', frame)
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    break
                elif key == ord(' '):
                    if not self.is_recording:
                        self.start_recording()
                elif key in [ord('1'), ord('2'), ord('3'), ord('4'), ord('5')]:
                    class_idx = key - ord('1')
                    if 0 <= class_idx < len(self.classes):
                        self.current_class = class_idx
                        print(f"ÄÃ£ chá»n: {self.class_names[self.classes[self.current_class]]}")
        finally:
            cap.release()
            cv2.destroyAllWindows()
            print(f"\n=== THá»NG KÃŠ CUá»I CÃ™NG ===")
            for cls in self.classes:
                print(f"  {self.class_names[cls]}: {self.stats[cls]} máº«u")
            print(f"Tá»•ng cá»™ng: {self.stats['total']} máº«u")

def main():
    """HÃ m chÃ­nh"""
    import argparse
    parser = argparse.ArgumentParser(description="Thu tháº­p dá»¯ liá»‡u dáº¥u thanh")
    parser.add_argument("--data-dir", default="data/tones", 
                       help="ThÆ° má»¥c lÆ°u dá»¯ liá»‡u")
    
    args = parser.parse_args()
    
    # Táº¡o collector
    collector = ToneDataCollector(args.data_dir)
    
    # Thu tháº­p dá»¯ liá»‡u
    collector.run()

if __name__ == "__main__":
    main()